// ==========================================
// üöÄ AI STUDY GENIUS - AZURE OPENAI SERVER
// üë®‚Äçüíª Desarrollado por: Vicentegg4212
// üìÖ Fecha: 2025-10-02 05:12:40 UTC
// ==========================================

import OpenAI from "openai";
import express from 'express';
import cors from 'cors';
import path from 'path';
import { fileURLToPath } from 'url';

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// ==========================================
// üîë CONFIGURACI√ìN DIRECTA (SIN .env)
// ==========================================

const CONFIG = {
    AZURE_OPENAI_API_KEY: "5AobTefY3p7mkeceBRQYdEQNtc6uz2F8Aio9fZ2iqDRvLh4thDeXJQQJ99BJACHYHv6XJ3w3AAAAACOGB4kA",  // üëà CAMBIA ESTO
    AZURE_OPENAI_ENDPOINT: "https://ceinnova05162-5325-resource.cognitiveservices.azure.com/",
    AZURE_OPENAI_DEPLOYMENT_NAME: "gpt-4o",
    API_VERSION: "2024-04-01-preview",
    PORT: 3000
};

console.log('\nüîç VERIFICANDO CONFIGURACI√ìN...');
console.log(`üîë API Key: ${CONFIG.AZURE_OPENAI_API_KEY ? '‚úÖ OK' : '‚ùå NO'}`);
console.log(`üåê Endpoint: ${CONFIG.AZURE_OPENAI_ENDPOINT ? '‚úÖ OK' : '‚ùå NO'}`);
console.log(`ü§ñ Deployment: ${CONFIG.AZURE_OPENAI_DEPLOYMENT_NAME}`);
console.log(`üö™ Puerto: ${CONFIG.PORT}\n`);

// Validaci√≥n de configuraci√≥n
if (!CONFIG.AZURE_OPENAI_API_KEY ) {
    console.error('‚ùå ERROR CR√çTICO: AZURE_OPENAI_API_KEY no configurada');
    console.error('üìù Abre server.js y cambia "TU_API_KEY_AQUI" por tu clave real');
    process.exit(1);
}

if (!CONFIG.AZURE_OPENAI_ENDPOINT) {
    console.error('‚ùå ERROR CR√çTICO: AZURE_OPENAI_ENDPOINT no configurado');
    process.exit(1);
}

// ==========================================
// ü§ñ INICIALIZAR CLIENTE AZURE OPENAI
// ==========================================

const client = new OpenAI({
    apiKey: CONFIG.AZURE_OPENAI_API_KEY,
    baseURL: `${CONFIG.AZURE_OPENAI_ENDPOINT}openai/deployments/${CONFIG.AZURE_OPENAI_DEPLOYMENT_NAME}`,
    defaultQuery: { 'api-version': CONFIG.API_VERSION },
    defaultHeaders: {
        'api-key': CONFIG.AZURE_OPENAI_API_KEY,
    }
});

console.log('‚úÖ Cliente Azure OpenAI inicializado correctamente\n');

// ==========================================
// üåê CONFIGURAR EXPRESS
// ==========================================

const app = express();

app.use(cors({
    origin: '*',
    methods: ['GET', 'POST', 'OPTIONS'],
    allowedHeaders: ['Content-Type', 'Accept']
}));

app.use(express.json({ limit: '50mb' }));
app.use(express.urlencoded({ extended: true, limit: '50mb' }));

// Servir archivos est√°ticos desde la ra√≠z del proyecto
const projectRoot = path.resolve(__dirname, '../../');
app.use(express.static(projectRoot));

console.log(`üìÇ Sirviendo archivos est√°ticos desde: ${projectRoot}`);

// ==========================================
// üì° ENDPOINTS DE LA API
// ==========================================

// Health Check
app.get('/api/health', (req, res) => {
    console.log('üè• Health check recibido');
    res.json({
        status: 'online',
        timestamp: new Date().toISOString(),
        user: 'Vicentegg4212',
        version: '2.0.0',
        azure_openai: {
            endpoint: CONFIG.AZURE_OPENAI_ENDPOINT,
            deployment: CONFIG.AZURE_OPENAI_DEPLOYMENT_NAME,
            api_version: CONFIG.API_VERSION
        }
    });
});

// Endpoint principal para generar respuestas
app.post('/api/generate', async (req, res) => {
    const requestId = `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const startTime = Date.now();

    console.log(`\nüì® [${requestId}] Nueva petici√≥n recibida`);
    console.log(`‚è∞ Timestamp: ${new Date().toISOString()}`);

    try {
        const { history = [], lastMessage, imageB64 } = req.body;

        if (!lastMessage && !imageB64) {
            console.error(`‚ùå [${requestId}] Error: No se proporcion√≥ mensaje ni imagen`);
            return res.status(400).json({
                error: 'Se requiere un mensaje o una imagen',
                request_id: requestId
            });
        }

        console.log(`üìù [${requestId}] Mensaje: "${lastMessage}"`);
        console.log(`üñºÔ∏è [${requestId}] Imagen: ${imageB64 ? 'S√≠' : 'No'}`);
        console.log(`üìö [${requestId}] Historial: ${history.length} mensajes`);

        // Construir mensajes para Azure OpenAI
        const messages = [
            {
                role: "system",
                content: `Eres un asistente educativo experto creado por Vicentegg4212. Tu funci√≥n es:
                
1. üìö Crear gu√≠as de estudio completas y estructuradas
2. üéØ Explicar conceptos de forma clara y concisa
3. üí° Proporcionar ejemplos pr√°cticos
4. üîç Analizar im√°genes de apuntes, libros, problemas
5. ‚úÖ Resolver dudas acad√©micas

Formato de respuesta:
- Usa emojis para mejor visualizaci√≥n
- Estructura con t√≠tulos y subt√≠tulos claros
- Incluye ejemplos cuando sea necesario
- S√© conciso pero completo

Recuerda: Eres un tutor amigable pero profesional.`
            }
        ];

        // Agregar historial previo
        history.forEach(msg => {
            if (msg.role && msg.content) {
                messages.push({
                    role: msg.role,
                    content: msg.content
                });
            }
        });

        // Agregar mensaje actual (con o sin imagen)
        if (imageB64) {
            messages.push({
                role: "user",
                content: [
                    { type: "text", text: lastMessage || "Analiza esta imagen y crea una gu√≠a de estudio" },
                    { type: "image_url", image_url: { url: imageB64 } }
                ]
            });
        } else {
            messages.push({
                role: "user",
                content: lastMessage
            });
        }

        console.log(`ü§ñ [${requestId}] Enviando a Azure OpenAI...`);

        // Llamada a Azure OpenAI con streaming
        const response = await client.chat.completions.create({
            messages: messages,
            model: CONFIG.AZURE_OPENAI_DEPLOYMENT_NAME,
            max_tokens: 4096,
            temperature: 0.7,
            top_p: 0.95,
            stream: true
        });

        const processingTime = Date.now() - startTime;

        // Configurar headers para streaming
        res.writeHead(200, {
            'Content-Type': 'text/plain; charset=utf-8',
            'Transfer-Encoding': 'chunked',
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*',
            'Access-Control-Allow-Headers': 'Content-Type'
        });

        let fullText = '';
        let tokenCount = 0;

        try {
            for await (const chunk of response) {
                const delta = chunk.choices[0]?.delta?.content;
                if (delta) {
                    fullText += delta;
                    tokenCount++;
                    
                    // Enviar chunk al cliente
                    const chunkData = JSON.stringify({
                        type: 'chunk',
                        content: delta,
                        request_id: requestId
                    }) + '\n';
                    
                    res.write(chunkData);
                }
            }

            // Enviar mensaje final
            const finalData = JSON.stringify({
                type: 'complete',
                guide: fullText,
                text: fullText,
                timestamp: new Date().toISOString(),
                request_id: requestId,
                processing_time_ms: Date.now() - startTime,
                word_count: fullText.split(/\s+/).length,
                model_used: CONFIG.AZURE_OPENAI_DEPLOYMENT_NAME,
                user: 'Vicentegg4212',
                usage: {
                    completion_tokens: tokenCount,
                    total_tokens: tokenCount
                }
            }) + '\n';

            res.write(finalData);
            res.end();

            console.log(`‚úÖ [${requestId}] Streaming completado exitosamente`);
            console.log(`‚è±Ô∏è [${requestId}] Tiempo total: ${Date.now() - startTime}ms`);
            console.log(`üìä [${requestId}] Tokens streamed: ${tokenCount}`);

        } catch (streamError) {
            console.error(`‚ùå [${requestId}] Error durante streaming:`, streamError);
            
            const errorData = JSON.stringify({
                type: 'error',
                error: 'Error durante streaming',
                details: streamError.message,
                request_id: requestId
            }) + '\n';
            
            res.write(errorData);
            res.end();
        }

    } catch (error) {
        const processingTime = Date.now() - startTime;
        
        console.error(`\n‚ùå [${requestId}] ERROR EN AZURE OPENAI:`);
        console.error(`üìõ Tipo: ${error.name}`);
        console.error(`üìù Mensaje: ${error.message}`);
        console.error(`‚è±Ô∏è Tiempo antes del error: ${processingTime}ms`);
        
        if (error.response) {
            console.error(`üì¶ Status: ${error.response.status}`);
            console.error(`üìÑ Data:`, error.response.data);
        }

        let errorMessage = 'Error al generar respuesta';
        let statusCode = 500;

        if (error.message.includes('API key')) {
            errorMessage = 'Error de autenticaci√≥n: Verifica tu API key';
            statusCode = 401;
        } else if (error.message.includes('quota') || error.message.includes('rate limit')) {
            errorMessage = 'L√≠mite de uso excedido. Intenta m√°s tarde.';
            statusCode = 429;
        } else if (error.message.includes('timeout')) {
            errorMessage = 'Tiempo de espera agotado. Intenta de nuevo.';
            statusCode = 504;
        }

        res.status(statusCode).json({
            error: errorMessage,
            details: error.message,
            request_id: requestId,
            timestamp: new Date().toISOString(),
            processing_time_ms: processingTime
        });
    }
});

// Endpoint para streaming de respuestas
app.post('/api/generate-stream', async (req, res) => {
    const requestId = `req_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
    const startTime = Date.now();

    console.log(`\nüì® [${requestId}] Nueva petici√≥n STREAMING recibida`);

    try {
        const { history = [], lastMessage, imageB64 } = req.body;

        if (!lastMessage && !imageB64) {
            return res.status(400).json({
                error: 'Se requiere un mensaje o una imagen',
                request_id: requestId
            });
        }

        // Construir mensajes para Azure OpenAI
        const messages = [
            {
                role: "system",
                content: `Eres un asistente educativo experto creado por Vicentegg4212. Responde de forma clara y estructurada.`
            }
        ];

        // Agregar historial previo
        history.forEach(msg => {
            if (msg.role && msg.content) {
                messages.push({
                    role: msg.role,
                    content: msg.content
                });
            }
        });

        // Agregar mensaje actual
        if (imageB64) {
            messages.push({
                role: "user",
                content: [
                    { type: "text", text: lastMessage || "Analiza esta imagen" },
                    { type: "image_url", image_url: { url: imageB64 } }
                ]
            });
        } else {
            messages.push({
                role: "user",
                content: lastMessage
            });
        }

        // Llamada a Azure OpenAI con streaming
        const response = await client.chat.completions.create({
            messages: messages,
            model: CONFIG.AZURE_OPENAI_DEPLOYMENT_NAME,
            max_tokens: 4096,
            temperature: 0.7,
            stream: true
        });

        // Configurar headers para streaming
        res.writeHead(200, {
            'Content-Type': 'text/plain; charset=utf-8',
            'Transfer-Encoding': 'chunked',
            'Cache-Control': 'no-cache',
            'Access-Control-Allow-Origin': '*'
        });

        let fullText = '';

        for await (const chunk of response) {
            const delta = chunk.choices[0]?.delta?.content;
            if (delta) {
                fullText += delta;
                
                const chunkData = JSON.stringify({
                    type: 'chunk',
                    content: delta,
                    request_id: requestId
                }) + '\n';
                
                res.write(chunkData);
            }
        }

        // Enviar mensaje final
        const finalData = JSON.stringify({
            type: 'complete',
            guide: fullText,
            timestamp: new Date().toISOString(),
            request_id: requestId,
            processing_time_ms: Date.now() - startTime,
            word_count: fullText.split(/\s+/).length
        }) + '\n';

        res.write(finalData);
        res.end();

    } catch (error) {
        console.error('Error en streaming:', error);
        res.status(500).json({
            error: 'Error en streaming',
            details: error.message,
            request_id: requestId
        });
    }
});

// Ruta principal - Servir index.html
app.get('/', (req, res) => {
    const indexPath = path.join(projectRoot, 'index.html');
    console.log(`üìÑ Sirviendo index.html desde: ${indexPath}`);
    res.sendFile(indexPath);
});

// Manejo de errores 404
app.use((req, res) => {
    console.log(`‚ùå 404 - Ruta no encontrada: ${req.method} ${req.url}`);
    res.status(404).json({
        error: 'Ruta no encontrada',
        path: req.url,
        timestamp: new Date().toISOString()
    });
});

// ==========================================
// üöÄ INICIAR SERVIDOR
// ==========================================

const server = app.listen(CONFIG.PORT, () => {
    console.log('\n‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó');
    console.log('‚ïë  üöÄ AI STUDY GENIUS - AZURE OPENAI SERVER  ‚ïë');
    console.log('‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù');
    console.log(`\n‚úÖ Servidor ejecut√°ndose correctamente`);
    console.log(`üìç URL: http://localhost:${CONFIG.PORT}`);
    console.log(`üë®‚Äçüíª Desarrollado por: Vicentegg4212`);
    console.log(`üìÖ Fecha: ${new Date().toISOString()}`);
    console.log(`ü§ñ Modelo: ${CONFIG.AZURE_OPENAI_DEPLOYMENT_NAME}`);
    console.log(`üåê Endpoint: ${CONFIG.AZURE_OPENAI_ENDPOINT}`);
    console.log(`\nüí° Presiona Ctrl+C para detener el servidor\n`);
});

// Manejo de cierre graceful
process.on('SIGTERM', () => {
    console.log('\n‚ö†Ô∏è Se√±al SIGTERM recibida. Cerrando servidor...');
    server.close(() => {
        console.log('‚úÖ Servidor cerrado correctamente');
        process.exit(0);
    });
});

process.on('SIGINT', () => {
    console.log('\n‚ö†Ô∏è Se√±al SIGINT recibida (Ctrl+C). Cerrando servidor...');
    server.close(() => {
        console.log('‚úÖ Servidor cerrado correctamente');
        process.exit(0);
    });
});

export default app;